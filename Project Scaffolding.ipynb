{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "from math import sin, cos, sqrt, atan2, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "SHP = gpd.read_file(\"/Users/wesley/Desktop/Columbia_2022_fall/IEOR4501/Final Project/taxi_zones.shp\")\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a67fc6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/18nnk14x26xd0hw8_j7261xw0000gn/T/ipykernel_24382/1150329011.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  SHP['pick_lon'] = SHP['geometry'].to_crs(4326).centroid.x\n",
      "/var/folders/_s/18nnk14x26xd0hw8_j7261xw0000gn/T/ipykernel_24382/1150329011.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  SHP['pick_lat'] = SHP['geometry'].to_crs(4326).centroid.y\n",
      "/var/folders/_s/18nnk14x26xd0hw8_j7261xw0000gn/T/ipykernel_24382/1150329011.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  SHP['drop_lon'] = SHP['geometry'].to_crs(4326).centroid.x\n",
      "/var/folders/_s/18nnk14x26xd0hw8_j7261xw0000gn/T/ipykernel_24382/1150329011.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  SHP['drop_lat'] = SHP['geometry'].to_crs(4326).centroid.y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.691831</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.691831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "      <td>-73.831299</td>\n",
       "      <td>40.616745</td>\n",
       "      <td>-73.831299</td>\n",
       "      <td>40.616745</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "      <td>-73.847422</td>\n",
       "      <td>40.864474</td>\n",
       "      <td>-73.847422</td>\n",
       "      <td>40.864474</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "      <td>-74.188484</td>\n",
       "      <td>40.552659</td>\n",
       "      <td>-74.188484</td>\n",
       "      <td>40.552659</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1025414.782 270986.139, 1025138.624 ...</td>\n",
       "      <td>-73.852215</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.852215</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1011466.966 216463.005, 1011545.889 ...</td>\n",
       "      <td>-73.906306</td>\n",
       "      <td>40.744235</td>\n",
       "      <td>-73.906306</td>\n",
       "      <td>40.744235</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((980555.204 196138.486, 980570.792 19...</td>\n",
       "      <td>-74.013023</td>\n",
       "      <td>40.709139</td>\n",
       "      <td>-74.013023</td>\n",
       "      <td>40.709139</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((999804.795 224498.527, 999824....</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((997493.323 220912.386, 997355.264 22...</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \\\n",
       "0              EWR  POLYGON ((933100.918 192536.086, 933091.011 19...   \n",
       "1           Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...   \n",
       "2            Bronx  POLYGON ((1026308.770 256767.698, 1026495.593 ...   \n",
       "3        Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...   \n",
       "4    Staten Island  POLYGON ((935843.310 144283.336, 936046.565 14...   \n",
       "..             ...                                                ...   \n",
       "258          Bronx  POLYGON ((1025414.782 270986.139, 1025138.624 ...   \n",
       "259         Queens  POLYGON ((1011466.966 216463.005, 1011545.889 ...   \n",
       "260      Manhattan  POLYGON ((980555.204 196138.486, 980570.792 19...   \n",
       "261      Manhattan  MULTIPOLYGON (((999804.795 224498.527, 999824....   \n",
       "262      Manhattan  POLYGON ((997493.323 220912.386, 997355.264 22...   \n",
       "\n",
       "      pick_lon   pick_lat   drop_lon   drop_lat  PULocationID  DOLocationID  \n",
       "0   -74.174000  40.691831 -74.174000  40.691831             1             1  \n",
       "1   -73.831299  40.616745 -73.831299  40.616745             2             2  \n",
       "2   -73.847422  40.864474 -73.847422  40.864474             3             3  \n",
       "3   -73.976968  40.723752 -73.976968  40.723752             4             4  \n",
       "4   -74.188484  40.552659 -74.188484  40.552659             5             5  \n",
       "..         ...        ...        ...        ...           ...           ...  \n",
       "258 -73.852215  40.897932 -73.852215  40.897932           259           259  \n",
       "259 -73.906306  40.744235 -73.906306  40.744235           260           260  \n",
       "260 -74.013023  40.709139 -74.013023  40.709139           261           261  \n",
       "261 -73.946510  40.775932 -73.946510  40.775932           262           262  \n",
       "262 -73.951010  40.778766 -73.951010  40.778766           263           263  \n",
       "\n",
       "[263 rows x 13 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SHP_prepare(SHP):\n",
    "    SHP['PULocationID'] = SHP['LocationID']\n",
    "    SHP['DOLocationID'] = SHP['LocationID']\n",
    "    SHP['pick_lon'] = SHP['geometry'].to_crs(4326).centroid.x\n",
    "    SHP['pick_lat'] = SHP['geometry'].to_crs(4326).centroid.y\n",
    "    SHP['drop_lon'] = SHP['geometry'].to_crs(4326).centroid.x\n",
    "    SHP['drop_lat'] = SHP['geometry'].to_crs(4326).centroid.y\n",
    "    return SHP\n",
    "\n",
    "SHP_trans = SHP_prepare(SHP)\n",
    "SHP_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e031bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the coordinates if there is only locationID and append the coordinate column to the dataframe\n",
    "def get_coord(df, SHP):\n",
    "\n",
    "    #drop the records with null values in locationID\n",
    "    try: \n",
    "        df.dropna(axis=0, how= 'any', subset = ['PULocationID', 'DOLocationID'], inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if ('PULocationID' in df.columns) and ('DOLocationID' in df.columns): #if only the zone ID is given\n",
    "        df = pd.merge(df, SHP[['PULocationID', 'pick_lon', 'pick_lat']], left_on = 'PULocationID', right_on = 'PULocationID', how = 'left')\n",
    "        df = pd.merge(df, SHP[['DOLocationID', 'drop_lon', 'drop_lat']], left_on = 'DOLocationID', right_on = 'DOLocationID', how = 'left')\n",
    "        \n",
    "    df.dropna(axis=0, how= 'any', subset = ['pick_lon', 'pick_lat'], inplace=True)\n",
    "    df = df.loc[(df['pick_lon'] <= -73.717047) & (df['pick_lon'] >= -74.242330) & (df['drop_lon'] <= -73.717047) & (df['drop_lon'] >= -74.242330) \n",
    "            & (df['pick_lat'] >= 40.560445) & (df['pick_lat'] <= 40.908524) & (df['drop_lat'] >= 40.560445) & (df['drop_lat'] <= 40.908524)]\n",
    "    return df\n",
    "         \n",
    "\n",
    "\n",
    "taxi_data_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet\"\n",
    "\n",
    "response = requests.get(taxi_data_url, stream=True)\n",
    "with open(\"lecture_08_taxi_data.parquet\", \"wb\") as f:\n",
    "    for chunk in response.iter_content(chunk_size=1024): \n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "data = pd.read_parquet('lecture_08_taxi_data.parquet', engine='pyarrow')\n",
    "\n",
    "df = get_coord(data, SHP_trans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(pick_lon, pick_lat, drop_lon, drop_lat):\n",
    "    R = 6373.0 #approximate earth radius\n",
    "\n",
    "    lat1 = radians(pick_lat)\n",
    "    lon1 = radians(pick_lon)\n",
    "    lat2 = radians(drop_lat)\n",
    "    lon2 = radians(drop_lon)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    #formula for calculating the distance (km)\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 00:02:00</td>\n",
       "      <td>2014-01-01 00:04:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 00:06:00</td>\n",
       "      <td>2014-01-01 00:09:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01 00:10:00</td>\n",
       "      <td>2014-01-01 00:13:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>-73.934829</td>\n",
       "      <td>40.754243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:29:18</td>\n",
       "      <td>2014-01-01 00:35:13</td>\n",
       "      <td>2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>229</td>\n",
       "      <td>262</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>2.650867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:36:33</td>\n",
       "      <td>2014-01-01 00:55:19</td>\n",
       "      <td>3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.954739</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.919694</td>\n",
       "      <td>40.761493</td>\n",
       "      <td>2.985577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786318</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31 23:22:15</td>\n",
       "      <td>2014-01-31 23:30:56</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>40.729506</td>\n",
       "      <td>3.679001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786319</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31 23:43:13</td>\n",
       "      <td>2014-02-01 00:12:35</td>\n",
       "      <td>1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>255</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.957418</td>\n",
       "      <td>40.718804</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>40.734576</td>\n",
       "      <td>4.214220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786320</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31 23:04:12</td>\n",
       "      <td>2014-01-31 23:11:15</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.968168</td>\n",
       "      <td>40.797962</td>\n",
       "      <td>2.163971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786321</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31 23:19:58</td>\n",
       "      <td>2014-01-31 23:29:45</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.987646</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.977569</td>\n",
       "      <td>40.764421</td>\n",
       "      <td>1.539240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13786322</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-31 23:33:41</td>\n",
       "      <td>2014-01-31 23:52:07</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.748428</td>\n",
       "      <td>2.155340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13545626 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0                2  2014-01-01 00:02:00   2014-01-01 00:04:00   \n",
       "1                2  2014-01-01 00:06:00   2014-01-01 00:09:00   \n",
       "2                2  2014-01-01 00:10:00   2014-01-01 00:13:00   \n",
       "4                1  2014-01-01 00:29:18   2014-01-01 00:35:13   \n",
       "5                1  2014-01-01 00:36:33   2014-01-01 00:55:19   \n",
       "...            ...                  ...                   ...   \n",
       "13786318         1  2014-01-31 23:22:15   2014-01-31 23:30:56   \n",
       "13786319         1  2014-01-31 23:43:13   2014-02-01 00:12:35   \n",
       "13786320         1  2014-01-31 23:04:12   2014-01-31 23:11:15   \n",
       "13786321         1  2014-01-31 23:19:58   2014-01-31 23:29:45   \n",
       "13786322         1  2014-01-31 23:33:41   2014-01-31 23:52:07   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                       6            0.0           1               None   \n",
       "1                       5            0.0           1               None   \n",
       "2                       5            0.0           1               None   \n",
       "4                       2            1.8           1                  N   \n",
       "5                       3            4.8           1                  N   \n",
       "...                   ...            ...         ...                ...   \n",
       "13786318                1            4.0           1                  N   \n",
       "13786319                1            4.1           1                  N   \n",
       "13786320                1            1.6           1                  N   \n",
       "13786321                1            1.6           1                  N   \n",
       "13786322                3            2.4           1                  N   \n",
       "\n",
       "          PULocationID  DOLocationID  payment_type  ...  tolls_amount  \\\n",
       "0                  146           146             1  ...           0.0   \n",
       "1                  146           146             1  ...           0.0   \n",
       "2                  146           146             1  ...           0.0   \n",
       "4                  229           262             2  ...           0.0   \n",
       "5                  140             7             2  ...           0.0   \n",
       "...                ...           ...           ...  ...           ...   \n",
       "13786318           148           112             1  ...           0.0   \n",
       "13786319           255           249             1  ...           0.0   \n",
       "13786320           236           151             1  ...           0.0   \n",
       "13786321           143           163             2  ...           0.0   \n",
       "13786322           161            68             1  ...           0.0   \n",
       "\n",
       "          improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                           0.0          4.52                   NaN   \n",
       "1                           0.0          4.55                   NaN   \n",
       "2                           0.0          4.58                   NaN   \n",
       "4                           0.0          8.50                   NaN   \n",
       "5                           0.0         18.50                   NaN   \n",
       "...                         ...           ...                   ...   \n",
       "13786318                    0.0         18.20                   NaN   \n",
       "13786319                    0.0         22.00                   NaN   \n",
       "13786320                    0.0         10.80                   NaN   \n",
       "13786321                    0.0         10.00                   NaN   \n",
       "13786322                    0.0         15.50                   NaN   \n",
       "\n",
       "          airport_fee   pick_lon   pick_lat   drop_lon   drop_lat  distance  \n",
       "0                None -73.934829  40.754243 -73.934829  40.754243  0.000000  \n",
       "1                None -73.934829  40.754243 -73.934829  40.754243  0.000000  \n",
       "2                None -73.934829  40.754243 -73.934829  40.754243  0.000000  \n",
       "4                None -73.965146  40.756729 -73.946510  40.775932  2.650867  \n",
       "5                None -73.954739  40.765484 -73.919694  40.761493  2.985577  \n",
       "...               ...        ...        ...        ...        ...       ...  \n",
       "13786318         None -73.990896  40.718938 -73.949540  40.729506  3.679001  \n",
       "13786319         None -73.957418  40.718804 -74.002875  40.734576  4.214220  \n",
       "13786320         None -73.957012  40.780436 -73.968168  40.797962  2.163971  \n",
       "13786321         None -73.987646  40.775965 -73.977569  40.764421  1.539240  \n",
       "13786322         None -73.977698  40.758028 -73.999917  40.748428  2.155340  \n",
       "\n",
       "[13545626 rows x 24 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_distance_column(df):\n",
    "    df['distance'] = df[[\"pick_lon\", \"pick_lat\", \"drop_lon\", \"drop_lat\"]].apply(lambda x: calculate_distance(*x), axis = 1)\n",
    "    return df\n",
    "\n",
    "add_distance_column(df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_taxi_parquet_links():\n",
    "    #construct the regrex expression list which contains the time in which we would like to analyze (2009-01 to 2015-06)\n",
    "    regrexlist = []\n",
    "    for y in range(2009, 2015):\n",
    "        for m in range(1, 13):\n",
    "            if m < 10:\n",
    "                m = '0' + str(m)\n",
    "            regrexlist.append(str(y) + '-' + str(m))\n",
    "    for m in range(1, 7):\n",
    "        regrexlist.append(str(2015) + '-' + '0' + str(m))\n",
    "\n",
    "    #get all the urls and filter with the regrex above\n",
    "    TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "    soup = bs4.BeautifulSoup(requests.get(TAXI_URL).content, 'html.parser')\n",
    "    a = soup.find_all('a')\n",
    "    res = []\n",
    "    for ele in a:\n",
    "        try:\n",
    "            if ele['title'] == 'Yellow Taxi Trip Records' :\n",
    "                for reg in regrexlist:\n",
    "                    if reg in ele['href']:\n",
    "                        res.append(ele['href'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return res\n",
    "\n",
    "find_taxi_parquet_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_csv_urls = find_taxi_csv_urls()\n",
    "    for csv_url in all_csv_url:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ym\n",
       "2009-01    2555\n",
       "2009-02    2292\n",
       "2009-03    2703\n",
       "2009-04    2574\n",
       "2009-05    2660\n",
       "           ... \n",
       "2015-02    2225\n",
       "2015-03    2362\n",
       "2015-04    2339\n",
       "2015-05    2449\n",
       "2015-06    2161\n",
       "Length: 78, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#find the sample size of uber\n",
    "uber = pd.read_csv(\"uber_rides_sample.csv\")\n",
    "uber.dropna(axis = 0, how = 'any', inplace = True)\n",
    "uber['pickup_datetime']\n",
    "uber['Ym'] = pd.to_datetime(uber['pickup_datetime']).dt.strftime('%Y-%m')\n",
    "uber.groupby(['Ym']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ad6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    \n",
    "    data=pd.read_csv(csv_file)\n",
    "    \n",
    "    #由于这是一个聚焦于小时的数据库，删去了所有daily和month的列\n",
    "    data=data.drop(data.columns[24:112],axis=1)\n",
    "    \n",
    "    #有几列只有一个值，没有意义，我全都删了\n",
    "    data=data.drop(columns=['STATION','LATITUDE','LONGITUDE','ELEVATION','NAME','BackupDirection','BackupDistance','BackupDistanceUnit','BackupElements','BackupElevation','BackupEquipment','BackupLatitude','BackupLongitude','BackupName','WindEquipmentChangeDate'])\n",
    "    \n",
    "    #有几列可用的数值实在太少，全都删去\n",
    "    data=data.drop(columns=['HourlyPrecipitation','HourlyPresentWeatherType','HourlySkyConditions','HourlyStationPressure','HourlyWetBulbTemperature','HourlyPressureChange','HourlyPressureTendency','HourlyWindGustSpeed'])\n",
    "    \n",
    "\n",
    "    #对于source这一列来说，只有取4才有意义，删去取0的行，然后将这一列删去\n",
    "    data=data[data['SOURCE']!=\"O\"]\n",
    "    data=data.drop(columns=['SOURCE'])\n",
    "    \n",
    "    #HourlyWindDirection这一项有一些VRB删去\n",
    "    data=data[data['HourlyWindDirection']!=\"VRB\"]\n",
    "    data[['HourlyWindDirection']]=data[['HourlyWindDirection']].astype('float64')\n",
    "    \n",
    "    #HourlyDewPointTemperature这一项有一些带s修改\n",
    "    data['HourlyDewPointTemperature']=data['HourlyDewPointTemperature'].apply( lambda x: str(x)[:-1] if str(x)[-1]=='s' else x)\n",
    "    data[['HourlyDewPointTemperature']]=data[['HourlyDewPointTemperature']].astype('float64')\n",
    "    \n",
    "    #HourlySeaLevelPressure这一项有一些带着s的修改\n",
    "    data['HourlySeaLevelPressure']=data['HourlySeaLevelPressure'].apply( lambda x: str(x)[:-1] if str(x)[-1]=='s' else x)\n",
    "    data[['HourlySeaLevelPressure']]=data[['HourlySeaLevelPressure']].astype('float64')\n",
    "  \n",
    "    #HourlyDryBulbTemperature这一项有一些带着s的修改\n",
    "    data['HourlyDryBulbTemperature']=data['HourlyDryBulbTemperature'].apply( lambda x: str(x)[:-1] if str(x)[-1]=='s' else x)\n",
    "    data[['HourlyDryBulbTemperature']]=data[['HourlyDryBulbTemperature']].astype('float64')\n",
    "\n",
    "    #HourlyVisibility这一项有一些带着V的要修改，不过这一列在daily里面也没让求取，不知道后续到底要干什么，但先予以保留\n",
    "    data['HourlyVisibility']=data['HourlyVisibility'].apply( lambda x: str(x)[:-1] if str(x)[-1]=='V' else x)\n",
    "    data[['HourlyVisibility']]=data[['HourlyVisibility']].astype('float64')\n",
    "\n",
    "    #删除空缺行\n",
    "    data=data.dropna(axis=0,how='any')\n",
    "    \n",
    "    #重新排列了一下index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    data=clean_month_weather_data_hourly(csv_file)\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    #提取日期并删除重复项\n",
    "    df['Date']=data['DATE']\n",
    "    df['Date']=df['Date'].apply(lambda x : x[0:10])\n",
    "    df['Date']=df.drop_duplicates()\n",
    "    df=df.dropna(axis=0,how='any')\n",
    "    \n",
    "    #重新排列了一下index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.set_index(['Date'],inplace=True)\n",
    "\n",
    "\n",
    "    #计算DailyAverageDewPointTemperature\n",
    "    data['Daily']=data['DATE'].apply(lambda x : x[0:10])\n",
    "    data_group=data.groupby('Daily')\n",
    "    DailyAverageDewPointTemperature=data_group.mean().iloc[:,0]\n",
    "    df['DailyAverageDewPointTemperature']=DailyAverageDewPointTemperature\n",
    "\n",
    "    #计算DailyAverageDryBulbTemperature\n",
    "    DailyAverageDryBulbTemperature=data_group.mean().iloc[:,1]\n",
    "    df['DailyAverageDryBulbTemperature']=DailyAverageDryBulbTemperature\n",
    "    \n",
    "    #计算DailyMaximumDryBulbTemperature\n",
    "    DailyMaximumDryBulbTemperature=data_group.max().iloc[:,4]\n",
    "    df['DailyMaximumDryBulbTemperature']=DailyMaximumDryBulbTemperature\n",
    "    \n",
    "    #计算DailyMinimumDryBulbTemperature\n",
    "    DailyMinimumDryBulbTemperature=data_group.min().iloc[:,4]\n",
    "    df['DailyMinimumDryBulbTemperature']=DailyMinimumDryBulbTemperature\n",
    "\n",
    "    #计算DailyAverageRelativeHumidity\n",
    "    DailyAverageRelativeHumidity=data_group.mean().iloc[:,2]\n",
    "    df['DailyAverageRelativeHumidity']=DailyAverageRelativeHumidity\n",
    "\n",
    "    #计算DailyAverageSeaLevelPressure\n",
    "    DailyAverageSeaLevelPressure=data_group.mean().iloc[:,3]\n",
    "    df['DailyAverageSeaLevelPressure']=DailyAverageSeaLevelPressure\n",
    "\n",
    "    #计算DailyAverageWindSpeed\n",
    "    DailyAverageWindSpeed=data_group.mean().iloc[:,6]\n",
    "    df['DailyAverageWindSpeed']=DailyAverageWindSpeed\n",
    "    \n",
    "    #计算DailyPeakWindSpeed\n",
    "    DailyPeakWindSpeed=data_group.max().iloc[:,9]\n",
    "    df['DailyPeakWindSpeed']=DailyPeakWindSpeed\n",
    "\n",
    "    #计算DailyPeakWindDirection 这个我没想出来方法如何计算，如果之后需要再回头考虑，其余变量同理\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data(n):\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    weather_csv_files=[]\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    for i in range(n):\n",
    "        weather_csv_files.append(r'{year}_weather.csv'.format(year=i+2009))\n",
    "\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "\n",
    "    #重新调整一下index \n",
    "    hourly_data.reset_index(drop=True, inplace=True)\n",
    "    daily_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_N = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_N).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_N, \"some_descriptive_name.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c64d787435b7a7ed91bf6c7246b7777ba2f470a2b271099e906ca111fdb42b0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
